|----F1: AA1 + PER (a=0.6, b=0.4, Max priority when added,  with random pretraining) -> F1a: clipped errors
|                                                                                    -> F1b: HIGH LR  
|                                                                                    -> F1c: clipped errors + HIGH LR + 200iteratios
|                                                                                    -> F1d: clipped errors + HIGHER LR + 200iteratios    
|                                                                                    -> F1e: clipped errors + HIGH LR + 200iteratios, a =0.8 
|                                                                                    -> F1f: clipped errors + HIGH LR + 200iteratios, a =0.4    

|
|----F0: AA1 + PER (a=0.6, b=0.4, Max priority when added,  no random pretraining) -> F0a: clipped errors
|                                                                                  -> F0b: HIGH LR
|
|----E0a1: AA1 + PER (a=0.6, b=0.4, no maximum priority for new samples, with random pretraining)
|
|
|----E0a0: AA1 + PER (a=0.6, b=0.4, no maximum priority for new samples, no random pretraining)---XXX
|
|
|XXXXXXXXXXXXXXXXXXX|----E0: AA1 + PER (a=0.6, b=0.4, MAX priority + error priority. BLUNDER?)--> E0a: Random exploration during initialization 
|
|
|
|     |----D3: Constant LR at 2.5E-3 (a=0.0, b=1.0)>> Should be equivalent to AA1a
|     |----D2: Constant LR at 2.5E-4 (a=0.0, b=1.0)>> Should be equivalent to AA1a with lower learning rate
|     |----D1: Constant LR at 2.5E-4 (a=0.6, b=0.4)
|     |
|----D0: AA1 + PER(a=0.6, b=0.4)
|
|---AA1a: Constant LR at 2.5E-4
|
|*******USING AA1 as CHECKPOINT*****************************************************************************************************
|
|----C3: A4 + PER(a=0.6,b=0.4), MSE LOSS, BATCH_SIZE=64
|
|----C2: A4 + PER(a=0.6,b=0.4), MSE LOSS, BATCH_SIZE=32
|
|----C1: A1 + PER(a=0.6,b=0.4), HUBER LOSS >>>OK but not optimal
|
|----C0: A0 + PER(a=0.6,b=0.4), MSE LOSS >>> OK but not optimal
|                     |
|                     |----C0a: (a=0.0, b=1):: EQUIVALENT TO A0 with lower LR >> OK but not optimal
|                     |
|                     |----C0b: (a=0.8, b=0.4)
|                     |
|                     |----C0c: (a=0.6, b=0.8)
|                     | 
|                     |----C0d: (a=0.8, b=0.8)
|
|
|
|
|----B0: Dueling Double DQN, MSE LOSS
|
|----B1: Dueling Double DQN, HUBER LOSS 
|  
|  
|  
|                                 |--- A3: OPTIMIZER = RMSPROP >>>> Better than A1
|                                 |
|                                 |
|                                 |--- A2: BATCH_SIZE = 32-------NOT_OK
|                                 |
|                                 | 
|---------------------A1: LOSS = HUBER LOSS >>>> OK
|                     
|
|                                       |---A4b: Easy Scheduling v3 >> Good Results
|                                       |---A4a: Easy Scheduling v1
|                                       |                                           |--AA2: Easy Scheduling v3
|                                       |                                           |--AA1: Easy Scheduling v2>>>>>>>>BEST RESULTS
|A4 is better than A5                   |                                           |
|---------------------A4: BATCH_SIZE = 32 >>>> BETTER THAN A0 ->>>>>>>>>>>>>>>>>>>>AA: General Reward Function
|
|
|
|                                      A5a: RMSPROP, BATCH_SIZE=32>>>> OK but not optimal
|                                       |
|                                       |
|---------------------A5: OPTIMIZER = RMSPROP >>>> BETTER THAN A0
|
|

|
|
#fixed stdize() CONSTANTS
#fixed weather forecast bug
********************************************************************
A0                                                                 *
********************************************************************
MODEL:                                                             *
A0        : INPUT->FC1->RELU->FC_OUT->OUTPUT                       *
LOSS      : MSE                                                    *
OPTIMIZER : ADAM                                                   *
RL        : Double DQN                                             * 
                                                                   *
LEARNING:   INIT_WEIGHT     = FC1 : KAIMING                        *
                              OUT : XAVIER                         *
            WIDTH           = 50                                   *
            DEPTH           = 1 + 1                                *
            WEIGHT_DECAY    = NONE                                 *
            LR              = LR SCHEDULING                        *
            UPDATE_FREQ     = 18 MONTHS                            *
            MEMORY          = 36 MONTHS                            *
            ITERATION       = 100                                  *
            BATCH_SIZE      = 32                                   *
            EPSILON         = EPSILON SCHEDULING                   *           
            GAMMA           = 0.9                                  *
            LAMBDA          = 0.95                                 *
                                                                   *
TRAINING:   TOKYO [2000-2009]                                      *
            SCHEDULING        = V3                                 *
            BATTERY_RESET     = 0%                                 *
            REWARD_FUNC       = 1d                                 *
            REWARD_BROADCAST  = TRUE                               *
            VIOLATION PENALTY = NONE                               *
                                                                   *
VALIDATION: TOKYO[2000-2018]                                       *
            GREEDY POLICY                                          *
********************************************************************

